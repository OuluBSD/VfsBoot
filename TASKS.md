# Tasks Tracker
Note: sexp is for AI and shell script is for human user (+ ai called via sexp). This follows the classic codex behaviour.


## Upcoming: important (in order)
- **[IN PROGRESS]** planner core engine for breakdown/context (action/state model, A* search, cost heuristics)
	- **[DONE]** Tag system implementation:
		- Enumerated tag registry (TagId = uint32_t) for memory efficiency
		- Tag storage separate from VfsNode (keeps nodes POD-friendly)
		- Tag commands: `tag.add`, `tag.remove`, `tag.list`, `tag.clear`, `tag.has`
		- All registered tags queryable, tags attached to any VFS node
	- **[DONE]** Hierarchical plan node types:
		- PlanRoot, PlanSubPlan, PlanGoals, PlanIdeas, PlanStrategy
		- PlanJobs (with priority, completion status, assignee tracking)
		- PlanDeps, PlanImplemented, PlanResearch, PlanNotes
		- All nodes support read/write as formatted text (markdown-style lists)
		- PlannerContext for navigation (forward/backward modes, history, visible nodes)
	- **[DONE]** Shell commands for plan management:
		- `plan.create <path> <type> [content]` - Create new plan node (root, subplan, goals, ideas, strategy, jobs, deps, implemented, research, notes)
		- `plan.goto <path>` - Navigate planner context
		- `plan.forward` / `plan.backward` - Change navigation mode
		- `plan.context.add/remove/clear/list` - Manage visible nodes for AI
		- `plan.jobs.add <path> <desc> [priority] [assignee]` - Add job to plan
		- `plan.jobs.complete <path> <index>` - Mark jobs as done
		- `plan.save [file]` - Save /plan tree to plan.vfs (default)
		- `plan.status` - Show current planner state
		- Auto-load plan.vfs on startup with /plan tree initialization
		- Full serialization/deserialization support for all PlanNode types
	- **[DONE]** Planning loop integration:
		- **[DONE]** Core `discuss` command (alias `ai.discuss`) with session management
		- **[DONE]** Intent classification (simple/planning/execution modes) with keyword heuristics
		- **[DONE]** Auto-routing: simple queries → direct AI, execution → plan tree, planning → breakdown
		- **[DONE]** Session tracking: random hex IDs, conversation history, plan path association
		- **[DONE]** Startup reminder to guide users to `discuss` command
		- **[DONE]** Interactive AI discussion workflow (plan.discuss integration)
			- Context-aware prompts for forward/backward modes
			- Automatic question parsing with Q: format detection
			- Integration with discuss session tracking
		- **[DONE]** Forward mode: add details to plans (root → leaves)
			- Auto-suggest next steps based on current location
			- Show child nodes and suggest drill-down paths
			- Guidance for creating goals/jobs/subplans
		- **[DONE]** Backward mode: revise higher-level plans when stuck
			- Navigate up plan tree with history tracking
			- Show parent paths and navigation suggestions
			- Focus on strategy revision and alternative approaches
		- **[DONE]** Yes/no/explain questions from human expert
			- plan.answer command for structured responses
			- Conversation history integration (last 6 messages)
			- Automatic follow-up question detection
		- **[DONE]** Hypothesis generation and testing integration
			- plan.hypothesis command with auto-detection from plan content
			- Creates hypothesis research nodes in plan tree
			- Suggests appropriate hypothesis.* commands based on plan keywords
		- **[TODO]** Advanced tree visualization with live line editing (codex/claude style)
	- **[TODO]** Context builder for AI calls:
		- Tag-based filtering for relevant nodes
		- Visibility tracking for nodes in current context
		- Smart context sizing (token budgets)
	- **[TODO]** Logic-based tag system with theorem proving for plan consistency:
		- **Tag mining workflow**: Extract user's mental model through minimal tag input
			- User provides initial tags (e.g., `fast`, `no-network`, `uses-cache`)
			- System infers implications and missing tags automatically
			- Detect contradictions early and suggest resolutions
		- **Implication engine**:
			- Hardcoded rules: `(rule (implies offline (not network)))`
			- Learned patterns from history: "fast usually implies cached (87% confidence)"
			- AI-generated implications: Ask LLM for domain-specific tag relationships
			- Forward-chaining inference to derive all logical consequences
		- **Consistency checking with theorem prover**:
			- Propositional logic solver (AND, OR, NOT, IMPLIES) for tag constraints
			- SAT/SMT integration (minisat or Z3) for complex constraint solving
			- Commands: `logic.assert <formula>`, `logic.check`, `logic.explain-conflict`
		- **Contradiction resolution**:
			- Detect conflicting tags before plan generation
			- Suggest alternatives: "Remove X, remove Y, or add bridging tag Z?"
			- Prune impossible plan branches during search
		- **Knowledge representation** in `/plan/rules`:
			- Tag definitions and logical relationships
			- Implication rules with confidence scores
			- Exclusion constraints (mutually exclusive tags)
			- Learned patterns from user feedback
		- **User feedback loop**:
			- Show inferred tags: "I assume you also want: [cached, local-only]. Correct?"
			- User confirms/rejects → refine inference rules
			- Build personalized tag ontology over time
		- **Integration with planner**:
			- Pre-planning: verify tag set is satisfiable
			- During planning: only generate consistent plan branches
			- Post-planning: verify AI-generated plan doesn't violate constraints
		- Use case: Prevent impossible plans like "build offline but fetch remote dependencies"
- **[DONE]** Advanced hypothesis testing examples (progressively more complex):
	- Implemented comprehensive hypothesis testing system with 5 complexity levels
	- **Level 1: Simple Query** - `hypothesis.query <target> [path]`
		- Find functions/patterns in VFS using ContextBuilder
		- Pattern matching across all VFS nodes
		- No AI calls required - pure VFS analysis
	- **Level 2: Code Modification** - `hypothesis.errorhandling <function> [style]`
		- Identify function definitions and return paths
		- Propose error handling strategies (try-catch, error-code, optional)
		- Analyze insertion points for error handling code
	- **Level 3: Refactoring** - `hypothesis.duplicates [path] [min_lines]`
		- Detect duplicate code blocks using similarity analysis
		- 80% similarity threshold with whitespace normalization
		- Propose extraction to helper functions with parameter inference
	- **Level 4: Feature Addition** - `hypothesis.logging [path]`
		- Identify error paths (return nullptr, -1, false, throw, error keywords)
		- Plan logging infrastructure and instrumentation points
		- Tag-based tracking for instrumented functions
	- **Level 5: Architecture** - `hypothesis.pattern <pattern> [path]`
		- Evaluate design pattern applicability (visitor, factory, singleton)
		- Analyze node hierarchies for visitor pattern suitability
		- Consider double-dispatch vs std::variant trade-offs
	- Shell commands: `test.hypothesis`, `hypothesis.test <level> <goal> [desc]`
	- Demo scripts: `scripts/examples/hypothesis-testing-demo.cx`, `hypothesis-demo-simple.cx`
	- All tests executable WITHOUT AI - uses ContextBuilder, filters, pattern matching
	- Integration with action planner's context builder for hypothesis validation
- scope store with binary diffs + feature masks, plus deterministic context builder
- scenario harness binaries (`planner_demo`, `planner_train`) and scripted breakdown loop for validation
- feedback pipeline for planner rule evolution (metrics capture, rule patch staging, optional AI assistance)
- integrate planner/context system into CLI once core pieces are stable
- add in-binary sample runner command `sample.run`
	- register `sample.run` in the shell command dispatcher so demos/tests can call it directly
	- reset `/astcpp/demo`, `/cpp/demo.cpp`, and `/logs/sample.*` before each run for deterministic state
	- construct the demo translation unit via C++ AST helpers and mirror the existing "Hello" program steps internally
	- dump the generated source back into `/cpp/demo.cpp` to keep user export workflows intact
	- locate the host compiler (from `/env/compiler`, env var, or default `c++`) and compile to a temporary executable
	- capture compiler stdout/stderr into VFS logs (`/logs/sample.compile.out`, `/logs/sample.compile.err`)
	- execute the compiled binary, recording output into `/logs/sample.run.out`, `/logs/sample.run.err`
	- write a status node (e.g. `/env/sample.status`) summarizing success/failure, exit codes, and timings
	- propagate failure by returning non-zero exit codes when compilation or execution fails
	- accept optional flags such as `--keep` or `--trace` for temp retention and verbose diagnostics
	- update documentation and scripts to reference `sample.run`, replacing the Makefile's external pipeline
	- extend automated tests to invoke `sample.run` and validate status/output log contents
- make
- parse (libclang): import clang test suite files to vfs
	- also collect what preprocessor sees
- web server app (Wt based) with graph-based visualization of AI operations (plan trees, VFS structure, AST nodes)
	- HTTP server exposing VFS state and planner context
	- Interactive graph rendering (D3.js/Cytoscape.js for plan trees and dependency graphs)
	- Real-time updates via WebSockets for live session monitoring
	- Image handling for AI vision tasks (upload/display/annotate)
	- Form-based interfaces for multi-step plan editing and hypothesis refinement

## Upcoming: less important
- commandline arguments: --llama, --openai, --version/-v, --help/-h, etc.
- explain different causes of sexp, cx, cxpkg files. discuss with me of them if you're unsure. write to README.md and AGENTS.md
	- make a solution with multiple cxasm & cxpkg packages, which all have multiple cpp and h files. compile and run it succesfully
- CLI home + end button usage while editing prompt
- when I press 'ä', it does nothing. fix it
- when I type "ai some message", I need to push enter twice instead of once
- sh compatibility, login shell (commandline -l), evaluate first if some additional flags are needed
- turing complete script (like bash, csh). Let's talk about syntax and grammar before implementing. I do want to have intuitive scripting and more like tcsh
- netcat -like client and server. Also like tty server for CLI. Have room for minimal SSH later
	- also oneliner for remote computer usage; one line would some "remote" command or something; advanced remote shell integration
	- also filetransfer like scp (but like nc = without additional layers (encryption etc.))
- some internal logs visible in /log (vfs)
- CLI autocomplete with tab
- ncurses (+ windows etc alternative) minimal text editor
- resolver for cpp ast nodes
	- keeping the codebase compatible with non-raii, dynamic memory typed languages, like java & C#
- add support for java & c# & typescript & javascript & python
- alias for script functions; e.g. cpp.returni could be like "cri"
- sexp to javascript to sexp converter
	- also for python, powershell, bash, etc.
	
## Upcoming: less important or skip altogether
- byte-vm (maybe overkill?) for sexp, or cx script

## Upcoming: important tests
- we should have small real-life examples, where we create "int main()". Then we need something new there couple of times: user -> system -> user -> system interaction; and the system searches and modifies the ast tree.
	- you should plan like 5 progressively more difficult interaction demos
- we should have actual programming project in a directory, with multiple files, which is mounted to the vfs as overlay. the code is kept both in persistent vfs-file and as cpp/h/Makefile files

##

## Completed
- **Hypothesis Testing System - 5 Progressive Complexity Levels** (2025-10-08):
  - Implemented comprehensive hypothesis testing framework for code analysis WITHOUT AI calls
  - **Level 1: Simple Query** (`hypothesis.query <target> [path]`)
    - VFS-wide pattern search using ContextBuilder and filters
    - Returns matched nodes with paths for further investigation
    - Example: Find all occurrences of a function name across codebase
  - **Level 2: Code Modification** (`hypothesis.errorhandling <function> [style]`)
    - Function definition detection with regex-based AST analysis
    - Return path identification for error handling insertion points
    - Multiple error handling strategies: try-catch, error-code, std::optional
    - Proposes specific actions for each identified insertion point
  - **Level 3: Refactoring** (`hypothesis.duplicates [path] [min_lines]`)
    - Duplicate code block detection using line-by-line similarity analysis
    - 80% similarity threshold with whitespace normalization
    - Proposes helper function extraction with parameter signature inference
    - Identifies all locations requiring refactoring updates
  - **Level 4: Feature Addition** (`hypothesis.logging [path]`)
    - Error path detection via pattern matching (return nullptr, -1, false, throw, error/fail keywords)
    - Logging instrumentation planning with context-aware placement
    - Proposes logger infrastructure design (class vs macros)
    - Tag-based tracking for instrumented code
  - **Level 5: Architecture** (`hypothesis.pattern <pattern> [path]`)
    - Design pattern applicability evaluation (visitor, factory, singleton)
    - Node hierarchy analysis for visitor pattern suitability
    - Implementation strategy proposals (double-dispatch vs std::variant vs CRTP)
    - Performance and migration considerations
  - Core components: Hypothesis, HypothesisResult, HypothesisTester, HypothesisTestSuite
  - Shell commands: test.hypothesis (run all 5), hypothesis.test (custom), hypothesis.{query,errorhandling,duplicates,logging,pattern}
  - Helper methods: findFunctionDefinitions, findReturnPaths, findDuplicateBlocks, findErrorPaths, contentSimilar
  - Demo scripts: scripts/examples/hypothesis-testing-demo.cx, hypothesis-demo-simple.cx
  - Integration with action planner's ContextBuilder for VFS traversal and filtering
  - All hypothesis testing executes locally - no AI API calls required
  - Enables hypothesis-driven development: validate code modification strategies before implementation
  - Foundation for advanced planning: SAT/SMT constraint solving, learned patterns, automated refactoring
- **Action Planner Test Suite - AI Context Builder** (2025-10-08):
  - Implemented ContextFilter with 9 filter types: TagAny, TagAll, TagNone, PathPrefix, PathPattern, ContentMatch, ContentRegex, NodeKind, Custom
  - Implemented ContextBuilder for building AI context with token budget management (default 4000 tokens)
  - Priority-based context selection: critical=200, important=150, default=100
  - Token estimation: ~4 chars per token (GPT-style tokenization)
  - Multi-overlay support: handles multiple VFS overlays transparently
  - Implemented ReplacementStrategy with 8 strategy types:
    - ReplaceAll, ReplaceRange, ReplaceFunction, InsertBefore, InsertAfter, DeleteMatching, CommentOut, ReplaceBlock (TODO)
  - Implemented ActionPlannerTestSuite with 6 comprehensive tests:
    - tag_filter_any, path_prefix, content_match, context_builder_tokens, replacement_all, replacement_insert_before
  - Added shell commands: context.build, context.filter.tag, context.filter.path, test.planner
  - Created comprehensive documentation: docs/ACTION_PLANNER.md
  - Created demonstration script: scripts/examples/action-planner-demo.cx
  - All tests passing (6/6 passed in test.planner)
  - This is the "AI context offloader" from TASKS.md - filters VFS nodes, builds context within token budgets, tests hypotheses before calling AI
  - Enables hypothesis-driven development: test code modification strategies without AI calls
  - Foundation for advanced features: tag-based theorem proving, SAT/SMT integration, learned patterns
- **Remote VFS mounting over network** (2025-10-08):
  - Implemented RemoteNode for transparent remote VFS access via TCP sockets
  - Added daemon mode: `--daemon <port>` to run codex as server accepting remote connections
  - EXEC protocol: line-based command execution (EXEC <cmd> → OK <output> | ERR <msg>)
  - mount.remote command: `mount.remote <host> <port> <remote-vfs-path> <local-vfs-path>`
  - Thread-safe socket communication with connection pooling and lazy connection
  - Integration with mount system: MountType::Remote, 'r' type marker in mount.list
  - Remote commands executed via shell (popen) allowing VFS and system command access
  - Use case: copy files between real filesystems on different hosts via VFS layer
  - Created demonstration scripts: remote-mount-demo.cx, remote-copy-demo.cx
  - Comprehensive documentation in docs/REMOTE_VFS.md
  - Updated README.md, AGENTS.md, HOWTO_SCRIPTS.md with remote mount examples
  - Note: libssh available but TCP-only implementation prioritized for simplicity
  - Future enhancements: SSH/SFTP transport, authentication, background I/O threads
- **Filesystem and library mounting** (2025-10-08):
  - Implemented MountNode for transparent host filesystem access (read/write to real files and directories)
  - Implemented LibraryNode for .so/.dll shared library loading via dlopen/dlsym
  - Added mount commands: mount, mount.lib, mount.list, mount.allow, mount.disallow, unmount
  - Mount nodes appear with type markers: m=filesystem mount, l=library
  - Created test shared library (tests/libtest.so) with 10 functions demonstrating various signatures
  - Added mount control system: mount.allow/mount.disallow gates new mounts without affecting existing ones
  - Mount tracking with MountInfo structure stores vfs_path, host_path, mount_node reference, and type
  - Updated documentation in AGENTS.md, README.md, and HOWTO_SCRIPTS.md
  - Created scripts/examples/mount-demo.cx demonstrating filesystem and library mounting
## Completed
- **VFS persistence with BLAKE3 hashing and autosave** (2025-10-07):
  - VFS overlay format upgraded to version 3 with BLAKE3 hash tracking for source files
  - Hash verification on .vfs load with mismatch warnings (compares stored hash with current file)
  - Auto-load `<dirname>.vfs` on startup when running in matching directory
  - Timestamped backups created in `.vfsh/` directory before overwriting (format: `file.vfs.YYYY-MM-DD-HHMMSS.bak`)
  - Autosave infrastructure for solution files (.cxpkg/.cxasm and their chained .vfs files):
    - Configurable delay (default 10 seconds after modification)
    - Only applies to solution packages, NOT standalone .vfs files
    - Background thread with dirty-flag tracking
  - Crash recovery snapshot framework (every 3 minutes to `.vfsh/recovery.vfs`)
  - Makefile updated to link libblake3
  - Note: Autosave thread startup and VFS write hooks still need integration in main()
## Completed
- **Test harness C++ compilation and execution** (2025-10-07):
  - test_harness.py now compiles generated C++ code using g++/c++ with -std=c++17 -O2
  - Added Linux sandbox execution using unshare (Gentoo-style) with timeout fallback for non-privileged environments
  - Implemented runtime output validation with `expected-runtime-output` field supporting contains/not-contains/equals assertions
  - All test .sexp files updated with runtime expectations for program output verification
  - Tests now verify actual program behavior (compilation + execution), not just AST structure
  - Sandbox provides network/PID namespace isolation on Linux, gracefully falls back to timeout-only when privileges unavailable
  - Compile timeout: 30s, execution timeout: 10s with automatic temp file cleanup
- Renamed Stage1 to VfsShell and updated all references (Makefile, header guards, documentation, test harness)
- Created VfsShell/AGENTS.md documenting implementation architecture (VFS design, S-expression language, C++ AST builder, AI bridge, code organization with line numbers, extension points)
- Linked VfsShell/AGENTS.md from root AGENTS.md under "Implementation details" section
- Created HOWTO_SCRIPTS.md with comprehensive examples for running all script files (.cx vs .sexp, running all scripts, creating custom scripts, common patterns, debugging)
- test_harness.py now uses AI response caching compatible with C++ cache format (cache/ai/{provider}/{hash}-in.txt and {hash}-out.txt)
- add shell commands ctrl+u and ctrl+k for clearing text
- AI bridge prompt & tests: added scripts/examples/ai-hello-world.sexp and tests/011-ai-bridge-hello.sexp to exercise cpp.* helpers via the ai command.
- `AGENTS.md` drafted from discussion notes to document VfsShell agent scope.
- Build tooling pipeline now operational:
  - Root `Makefile` builds the VfsShell binary and exposes debug/release toggles.
  - OpenAI integration loads the API key from the home directory fallback (`~/openai-key.txt`).
  - `make sample` exercises the C++ AST builder, exports generated code, compiles it, and checks the runtime output.
- VfsShell harness (`tools/test_harness.py`) runs `.sexp` specs end-to-end against configured LLM targets and validates results inside codex-mini.
- C++ AST shell surface now includes statements (`cpp.vardecl`, `cpp.expr`, `cpp.stmt`, `cpp.return`, `cpp.rangefor`) for structural codegen beyond canned print/return helpers.
- overlays: multiple persistent VFS overlays can now coexist without mixing nodes; the CLI exposes `overlay.*` commands and aggregate listings.

## Backlog / Ideas
- Harden string escaping in the C++ AST dumper before expanding code generation.
- VfsNode memory optimization: keep VfsNode POD-friendly (trivially copyable), implement fast recycler for construction/destruction (hot code path)
- GUI support: web-based interface using Wt libraries for forms, multiple questions at once, plan visualization
- Node metadata storage: separate from VfsNode to maintain POD compatibility (VFS-owned map pattern)
